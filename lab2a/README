NAME: Sean Langley
EMAIL: sean.langley22@gmail.com
UID: 504 661 838


PROJECT DESCRIPTION
===================
This tar file contains the following files: 
lab2_add.c -- source code for testing race conditions on a multiple threaded adding application
lab2_list.c -- sorce code for testing race conditions on a doubly sorted linked list application
SortedList.h -- header file describing an interface for linked list operations
SortedList.c -- Source code implementing the interface defined in SortedList.h
Makefile -- Provides builds for the executables
lab2_add.csv -- a csv file with many outputs of the lab2_add program
lab2_list.csv -- a csv file with many outputs of the lab2_list program
lab2_add-1.png -- threads required to generate a failure
lab2_add-2.png -- average time per operation with and without yields.
lab2_add-3.png -- average time per (single threaded) operation vs. the number of iterations.
lab2_add-4.png -- threads and iterations that can run successfully with yields under each of the synchronization options.
lab2_add-5.png -- average time per (protected) operation vs. the number of threads.
For part 2 (lab2_list):
lab2_list-1.png -- average time per (single threaded) unprotected operation vs. number of iterations (illustrating the correction of the per-operation cost for the list length).
lab2_list-2.png -- threads and iterations required to generate a failure (with and without yields).
lab2_list-3.png -- iterations that can run (protected) without failure.
lab2_list-4.png -- (length-adjusted) cost per operation vs the number of threads for the various synchronization options.



Change Notice -- I was having issues plotting lab2_add-5.png for an unknown reason, so I made some minor changes in the lab2_add.gp source file. I changed the last grep lines so that they gathered the correct data points.



Question Answers
===================================
QUESTION 2.1.1 -- causing conflicts:
Why does it take many iterations before errors are seen? 
Why does a significantly smaller number of iterations so seldom fail?


By nature, multiple threaded applications are non deterministic. This C program, lab2_add.c, increments and decrements a shared variable on multiple threads. Because these threads are running at the same time, their non deterministic nature can cause multiple additions to occur before a single subtraction to occur, creating an incorrect result. The non-deterministic nature of threaded applications greatly increases and the number of iterations increase i.e. the longer the program is allowed to execute.



===================================
QUESTION 2.1.2 -- cost of yielding:
Why are the --yield runs so much slower?
Where is the additional time going?
Is it possible to get valid per-operation timings if we are using the --yield option?
If so, explain how. If not, explain why not.


When we schedule a yield, the operating system needs to implement a context switch between threads. This consists of saving the thread's state, process counter, and any other information associated with the thread. It isn't possible to get valid per-operation timings while using the --yield option because most of the time is going into context switches rather than into the actual operations.

===================================
QUESTION 2.1.3 - measurement errors:
Why does the average cost per operation drop with increasing iterations?
If the cost per iteration is a function of the number of iterations, how do we know how many iterations to run (or what the "correct" cost is)?	
	 

As the number of iterations increase, the total average is more reflective of the time of each operation versus the overhead of setting up the program. In order to get a result that's more reflective of the time per operation, we should execute the program with as many iterations as possible, so the initial time of setting up the threads is averaged out with the time of each operation.


========================================
QUESTION 2.1.4 - costs of serialization:
Why do all of the options perform similarly for low numbers of threads?
Why do the three protected operations slow down as the number of threads rises?

With a low number of threads, there is a low number of overhead spend on the context switches between different threads. This becomes more significant with mutex variables and with locking. With mutex variables, threads spend a lot of time waiting for the variable to become free versus spending time on actual operations. 


=====================================
QUESTION 2.2.1 - scalability of Mutex
Compare the variation in time per mutex-protected operation vs the number of threads in Part-1 (adds) and Part-2 (sorted lists).
Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

In part 2, the the mutex lock is held for longer periods of time than in part 1, so the curve slopes upward as the number of threads increase. This is not the case for part 1 where the add operation is much faster than the linked list operations, so the lock is held for a much shorter period of time.


=========================================
QUESTION 2.2.2 - scalability of spin locks
Compare the variation in time per protected operation vs the number of threads for list operations protected by Mutex vs Spin locks. Comment on the general shapes of the curves, and explain why they have this shape.
Comment on the relative rates of increase and differences in the shapes of the curves, and offer an explanation for these differences.

As the number of threads increase, the time per operation increases for both spin locks and mutexes. However, the time per operation increases more quickly for spin locks than for mutexes. This is because the insert/delete operation is very long, so when a thread begins the thread function and gives up its execution to another thread, it spends a long time spinning which takes up cpu time and instructions. Mutexes are faster because a thread doesn't spend extra cpu time spinning while another thread is executing instructions.

